{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import pickle\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/factors_1965.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546907   \n",
      "1   10401 1965-02-26  35392058.00  0.780829  0.609694 -0.063768  12.240330   \n",
      "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
      "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
      "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240330   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
      "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
      "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
      "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
      "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "\n",
      "   macro_smb  \n",
      "0       3.55  \n",
      "1       3.55  \n",
      "2       3.55  \n",
      "3       3.55  \n",
      "4       3.55  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/factors_1970.csv', parse_dates=['DATE'])\n",
    "\n",
    "# LR-3 plus acc, roaq, aqr, and egr\n",
    "df = df[['DATE','permno','mom12m', 'mvel1', 'bm', 'acc', 'roaq', 'agr', 'egr','macro_tbl', 'macro_svar','risk_premium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>permno</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>bm</th>\n",
       "      <th>acc</th>\n",
       "      <th>roaq</th>\n",
       "      <th>agr</th>\n",
       "      <th>egr</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>risk_premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10401</td>\n",
       "      <td>-0.057315</td>\n",
       "      <td>26227356.0</td>\n",
       "      <td>0.796609</td>\n",
       "      <td>0.055965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.067613</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10604</td>\n",
       "      <td>-0.234695</td>\n",
       "      <td>3196008.0</td>\n",
       "      <td>0.245563</td>\n",
       "      <td>0.055042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.299523</td>\n",
       "      <td>0.072061</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>-11.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10786</td>\n",
       "      <td>-0.171812</td>\n",
       "      <td>1133566.5</td>\n",
       "      <td>1.379277</td>\n",
       "      <td>0.055042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>-1.9956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10890</td>\n",
       "      <td>0.359525</td>\n",
       "      <td>2662344.0</td>\n",
       "      <td>0.144765</td>\n",
       "      <td>0.055042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.293566</td>\n",
       "      <td>0.171707</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>-10.3290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>11260</td>\n",
       "      <td>-0.321664</td>\n",
       "      <td>1342376.0</td>\n",
       "      <td>0.794354</td>\n",
       "      <td>0.055042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.140970</td>\n",
       "      <td>0.126208</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>-10.4214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  permno    mom12m       mvel1        bm       acc  roaq  \\\n",
       "0 1970-02-27   10401 -0.057315  26227356.0  0.796609  0.055965   NaN   \n",
       "1 1970-02-27   10604 -0.234695   3196008.0  0.245563  0.055042   NaN   \n",
       "2 1970-02-27   10786 -0.171812   1133566.5  1.379277  0.055042   NaN   \n",
       "3 1970-02-27   10890  0.359525   2662344.0  0.144765  0.055042   NaN   \n",
       "4 1970-02-27   11260 -0.321664   1342376.0  0.794354  0.055042   NaN   \n",
       "\n",
       "        agr       egr  macro_tbl  macro_svar  risk_premium  \n",
       "0 -0.067613  0.038232     0.0713    0.001059        0.4798  \n",
       "1 -0.299523  0.072061     0.0713    0.001059      -11.7111  \n",
       "2  0.007556  0.014443     0.0713    0.001059       -1.9956  \n",
       "3 -0.293566  0.171707     0.0713    0.001059      -10.3290  \n",
       "4 -0.140970  0.126208     0.0713    0.001059      -10.4214  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "df['mvel12'] = df['mvel1'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.3 \n",
    "df_top= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_bottom = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "\n",
    "df[features] = 2*df[features] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(y_true, y_pred, in_sample=True, benchmark=None):\n",
    "    if in_sample:\n",
    "        return 1 - (np.sum((y_true - y_pred) ** 2) / \n",
    "                    np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "    else:\n",
    "        if benchmark is None:\n",
    "            raise ValueError(\"Benchmark must be provided for out-of-sample R-squared calculation.\")\n",
    "        return 1 - (np.sum((y_true - y_pred) ** 2) / \n",
    "                    np.sum((y_true - benchmark) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>permno</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>bm</th>\n",
       "      <th>acc</th>\n",
       "      <th>roaq</th>\n",
       "      <th>agr</th>\n",
       "      <th>egr</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>risk_premium</th>\n",
       "      <th>mvel12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE2</th>\n",
       "      <th>permno2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1970-02-27</th>\n",
       "      <th>10401</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10401</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10604</td>\n",
       "      <td>-0.676768</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.858586</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-11.7111</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10786</td>\n",
       "      <td>-0.373737</td>\n",
       "      <td>-0.696970</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>-0.959596</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-1.9956</td>\n",
       "      <td>-0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>10890</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>-0.696970</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.818182</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-10.3290</td>\n",
       "      <td>0.474747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>11260</td>\n",
       "      <td>-0.878788</td>\n",
       "      <td>-0.353535</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-10.4214</td>\n",
       "      <td>-0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-11-30</th>\n",
       "      <th>93380</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>93380</td>\n",
       "      <td>-0.914542</td>\n",
       "      <td>0.135768</td>\n",
       "      <td>-0.486561</td>\n",
       "      <td>0.774638</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.627843</td>\n",
       "      <td>0.532736</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-12.6545</td>\n",
       "      <td>0.135768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93419</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>93419</td>\n",
       "      <td>0.128877</td>\n",
       "      <td>-0.034459</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>-0.704342</td>\n",
       "      <td>-0.475534</td>\n",
       "      <td>-0.487939</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-5.5257</td>\n",
       "      <td>-0.034459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>93423</td>\n",
       "      <td>0.731909</td>\n",
       "      <td>-0.104755</td>\n",
       "      <td>-0.987595</td>\n",
       "      <td>-0.559614</td>\n",
       "      <td>-0.909717</td>\n",
       "      <td>0.769814</td>\n",
       "      <td>0.871813</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-11.1368</td>\n",
       "      <td>-0.104755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93427</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>93427</td>\n",
       "      <td>0.516885</td>\n",
       "      <td>-0.098553</td>\n",
       "      <td>-0.412819</td>\n",
       "      <td>0.600965</td>\n",
       "      <td>0.740868</td>\n",
       "      <td>-0.404549</td>\n",
       "      <td>0.507926</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>15.1167</td>\n",
       "      <td>-0.098553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>93436</td>\n",
       "      <td>0.745693</td>\n",
       "      <td>0.974156</td>\n",
       "      <td>-0.911096</td>\n",
       "      <td>-0.783598</td>\n",
       "      <td>-0.333563</td>\n",
       "      <td>-0.882839</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>2.7112</td>\n",
       "      <td>0.974156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675894 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DATE  permno    mom12m     mvel1        bm       acc  \\\n",
       "DATE2      permno2                                                              \n",
       "1970-02-27 10401   1970-02-27   10401 -0.030303  0.979798  0.939394  0.878788   \n",
       "           10604   1970-02-27   10604 -0.676768  0.575758 -0.414141  0.010101   \n",
       "           10786   1970-02-27   10786 -0.373737 -0.696970  0.959596  0.010101   \n",
       "           10890   1970-02-27   10890  0.898990  0.474747 -0.696970  0.010101   \n",
       "           11260   1970-02-27   11260 -0.878788 -0.353535  0.919192  0.010101   \n",
       "...                       ...     ...       ...       ...       ...       ...   \n",
       "2021-11-30 93380   2021-11-30   93380 -0.914542  0.135768 -0.486561  0.774638   \n",
       "           93419   2021-11-30   93419  0.128877 -0.034459  0.773260  0.495520   \n",
       "           93423   2021-11-30   93423  0.731909 -0.104755 -0.987595 -0.559614   \n",
       "           93427   2021-11-30   93427  0.516885 -0.098553 -0.412819  0.600965   \n",
       "           93436   2021-11-30   93436  0.745693  0.974156 -0.911096 -0.783598   \n",
       "\n",
       "                        roaq       agr       egr  macro_tbl  macro_svar  \\\n",
       "DATE2      permno2                                                        \n",
       "1970-02-27 10401         NaN  0.676768 -0.777778   0.010101    0.010101   \n",
       "           10604         NaN -0.858586 -0.272727   0.010101    0.010101   \n",
       "           10786         NaN  0.939394 -0.959596   0.010101    0.010101   \n",
       "           10890         NaN -0.818182  0.636364   0.010101    0.010101   \n",
       "           11260         NaN -0.333333  0.494949   0.010101    0.010101   \n",
       "...                      ...       ...       ...        ...         ...   \n",
       "2021-11-30 93380    0.000345 -0.627843  0.532736   0.000345    0.000345   \n",
       "           93419   -0.704342 -0.475534 -0.487939   0.000345    0.000345   \n",
       "           93423   -0.909717  0.769814  0.871813   0.000345    0.000345   \n",
       "           93427    0.740868 -0.404549  0.507926   0.000345    0.000345   \n",
       "           93436   -0.333563 -0.882839  0.963473   0.000345    0.000345   \n",
       "\n",
       "                    risk_premium    mvel12  \n",
       "DATE2      permno2                          \n",
       "1970-02-27 10401          0.4798  0.979798  \n",
       "           10604        -11.7111  0.575758  \n",
       "           10786         -1.9956 -0.696970  \n",
       "           10890        -10.3290  0.474747  \n",
       "           11260        -10.4214 -0.353535  \n",
       "...                          ...       ...  \n",
       "2021-11-30 93380        -12.6545  0.135768  \n",
       "           93419         -5.5257 -0.034459  \n",
       "           93423        -11.1368 -0.104755  \n",
       "           93427         15.1167 -0.098553  \n",
       "           93436          2.7112  0.974156  \n",
       "\n",
       "[675894 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1976-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 11430 ,# val records 6471 , # test records 4416\n",
      "Train period: 1977-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 13241 ,# val records 7309 , # test records 4368\n",
      "Train period: 1978-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 14193 ,# val records 8784 , # test records 4870\n",
      "Train period: 1979-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 16579 ,# val records 9238 , # test records 6416\n",
      "Train period: 1980-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 18589 ,# val records 11286 , # test records 6641\n",
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 20125 ,# val records 13057 , # test records 5931\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 22963 ,# val records 12572 , # test records 6850\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 26711 ,# val records 12781 , # test records 6553\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 28226 ,# val records 13403 , # test records 7063\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 30708 ,# val records 13616 , # test records 8743\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 32391 ,# val records 15806 , # test records 8628\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 33038 ,# val records 17371 , # test records 10193\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 35140 ,# val records 18821 , # test records 11176\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 37837 ,# val records 21369 , # test records 12945\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 41180 ,# val records 24121 , # test records 16010\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 45803 ,# val records 28955 , # test records 15949\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 51685 ,# val records 31959 , # test records 14847\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 58952 ,# val records 30796 , # test records 18389\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 66273 ,# val records 33236 , # test records 16233\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 70927 ,# val records 34622 , # test records 15449\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 78140 ,# val records 31682 , # test records 17642\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 81428 ,# val records 33091 , # test records 17980\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 80867 ,# val records 35622 , # test records 21590\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 82560 ,# val records 39570 , # test records 23521\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 85693 ,# val records 45111 , # test records 24470\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 88894 ,# val records 47991 , # test records 21949\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 96182 ,# val records 46419 , # test records 16767\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 105203 ,# val records 38716 , # test records 18170\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 109510 ,# val records 34937 , # test records 21578\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 108297 ,# val records 39748 , # test records 21516\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 104877 ,# val records 43094 , # test records 23877\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 102934 ,# val records 45393 , # test records 28640\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 99980 ,# val records 52517 , # test records 26461\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 101908 ,# val records 55101 , # test records 23187\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 113781 ,# val records 49648 , # test records 27102\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 122072 ,# val records 50289 , # test records 28421\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 123681 ,# val records 55523 , # test records 27271\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 129267 ,# val records 55692 , # test records 29168\n",
      "R2OOS Linear Regression Full:  0.0356603278204245\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'risk_premium'])]\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    lm = LinearRegression()\n",
    "   \n",
    "    lm.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    #Use test set to generate final predictions \n",
    "    preds = lm.predict(X_test)\n",
    "\n",
    "    #Save predictions, dates and the true values of the dependent variable to list  \n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test-preds,2))/np.sum(pow(y_test,2))\n",
    "\n",
    "    #Save OOS model performance and the respective month to dictionary\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "#Calculate OOS model performance over the entire test period in line with Gu et al (2020)\n",
    "R2OOS_LR = 1-np.sum(pow(y_test_list_all-predictions_all,2))/np.sum(pow(y_test_list_all,2))\n",
    "print(\"R2OOS Linear Regression Full: \", R2OOS_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1976-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1983-08-31 # train records 11430 ,# val records 6471 , # test records 2472\n",
      "Train period: 1977-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1984-08-31 # train records 13241 ,# val records 7309 , # test records 2536\n",
      "Train period: 1978-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1985-08-31 # train records 14193 ,# val records 8784 , # test records 3224\n",
      "Train period: 1979-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1986-08-31 # train records 16579 ,# val records 9238 , # test records 3926\n",
      "Train period: 1980-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1987-08-31 # train records 18589 ,# val records 11286 , # test records 3401\n",
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1988-08-31 # train records 20125 ,# val records 13057 , # test records 3245\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1989-08-31 # train records 22963 ,# val records 12572 , # test records 3911\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1990-08-31 # train records 26711 ,# val records 12781 , # test records 4002\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1991-08-31 # train records 28226 ,# val records 13403 , # test records 4591\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1992-08-31 # train records 30708 ,# val records 13616 , # test records 4613\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1993-08-31 # train records 32391 ,# val records 15806 , # test records 4553\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1994-08-31 # train records 33038 ,# val records 17371 , # test records 5920\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1995-08-31 # train records 35140 ,# val records 18821 , # test records 6209\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1996-08-31 # train records 37837 ,# val records 21369 , # test records 8494\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1997-08-31 # train records 41180 ,# val records 24121 , # test records 9425\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1998-08-31 # train records 45803 ,# val records 28955 , # test records 8456\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 1999-08-31 # train records 51685 ,# val records 31959 , # test records 7905\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2000-08-31 # train records 58952 ,# val records 30796 , # test records 10908\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2001-08-31 # train records 66273 ,# val records 33236 , # test records 9793\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2002-08-31 # train records 70927 ,# val records 34622 , # test records 10661\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2003-08-31 # train records 78140 ,# val records 31682 , # test records 10135\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2004-08-31 # train records 81428 ,# val records 33091 , # test records 9738\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2005-08-31 # train records 80867 ,# val records 35622 , # test records 12343\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2006-08-31 # train records 82560 ,# val records 39570 , # test records 13693\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2007-08-31 # train records 85693 ,# val records 45111 , # test records 14424\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2008-08-31 # train records 88894 ,# val records 47991 , # test records 14552\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2009-08-31 # train records 96182 ,# val records 46419 , # test records 7653\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2010-08-31 # train records 105203 ,# val records 38716 , # test records 9794\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2011-08-31 # train records 109510 ,# val records 34937 , # test records 12978\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2012-08-31 # train records 108297 ,# val records 39748 , # test records 12468\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2013-08-31 # train records 104877 ,# val records 43094 , # test records 15537\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2014-08-31 # train records 102934 ,# val records 45393 , # test records 17526\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2015-08-31 # train records 99980 ,# val records 52517 , # test records 13529\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2016-08-31 # train records 101908 ,# val records 55101 , # test records 12399\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2017-08-31 # train records 113781 ,# val records 49648 , # test records 15613\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2018-08-31 # train records 122072 ,# val records 50289 , # test records 16489\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2019-08-31 # train records 123681 ,# val records 55523 , # test records 18226\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2020-08-31 # train records 129267 ,# val records 55692 , # test records 15232\n",
      "Train period: 2014-01-31 - 2019-01-31 ,val period: 2019-01-31 - 2021-01-31 , Test period 2021-01-31 - 2021-08-31 # train records 133811 ,# val records 56439 , # test records 16308\n",
      "R2OOS Linear Regression Top:  0.024892869274369733\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'risk_premium'])]\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "predictions_top = []\n",
    "y_test_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_all_top = {}\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = lm.predict(X_test) \n",
    "    predictions_top.append(preds)\n",
    "    dates_top.append(y_test.index)\n",
    "    y_test_list_top.append(y_test)\n",
    "    \n",
    "    r2_top = 1-np.sum(pow(y_test-preds,2))/np.sum(pow(y_test,2))\n",
    "    dic_r2_all_top[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_top= np.concatenate(predictions_top, axis=0)\n",
    "y_test_list_all_top= np.concatenate(y_test_list_top, axis=0) \n",
    "dates_all_top= np.concatenate(dates_top, axis=0)\n",
    "\n",
    "R2OOS_LR_top = 1-np.sum(pow(y_test_list_all_top-predictions_all_top,2))/np.sum(pow(y_test_list_all_top,2))\n",
    "print(\"R2OOS Linear Regression Top: \", R2OOS_LR_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1976-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1983-08-31 # train records 11430 ,# val records 6471 , # test records 2472\n",
      "Train period: 1977-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1984-08-31 # train records 13241 ,# val records 7309 , # test records 2536\n",
      "Train period: 1978-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1985-08-31 # train records 14193 ,# val records 8784 , # test records 3224\n",
      "Train period: 1979-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1986-08-31 # train records 16579 ,# val records 9238 , # test records 3926\n",
      "Train period: 1980-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1987-08-31 # train records 18589 ,# val records 11286 , # test records 3401\n",
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1988-08-31 # train records 20125 ,# val records 13057 , # test records 3245\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1989-08-31 # train records 22963 ,# val records 12572 , # test records 3911\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1990-08-31 # train records 26711 ,# val records 12781 , # test records 4002\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1991-08-31 # train records 28226 ,# val records 13403 , # test records 4591\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1992-08-31 # train records 30708 ,# val records 13616 , # test records 4613\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1993-08-31 # train records 32391 ,# val records 15806 , # test records 4553\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1994-08-31 # train records 33038 ,# val records 17371 , # test records 5920\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1995-08-31 # train records 35140 ,# val records 18821 , # test records 6209\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1996-08-31 # train records 37837 ,# val records 21369 , # test records 8494\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1997-08-31 # train records 41180 ,# val records 24121 , # test records 9425\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1998-08-31 # train records 45803 ,# val records 28955 , # test records 8456\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 1999-08-31 # train records 51685 ,# val records 31959 , # test records 7905\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2000-08-31 # train records 58952 ,# val records 30796 , # test records 10908\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2001-08-31 # train records 66273 ,# val records 33236 , # test records 9793\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2002-08-31 # train records 70927 ,# val records 34622 , # test records 10661\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2003-08-31 # train records 78140 ,# val records 31682 , # test records 10135\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2004-08-31 # train records 81428 ,# val records 33091 , # test records 9738\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2005-08-31 # train records 80867 ,# val records 35622 , # test records 12343\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2006-08-31 # train records 82560 ,# val records 39570 , # test records 13693\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2007-08-31 # train records 85693 ,# val records 45111 , # test records 14424\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2008-08-31 # train records 88894 ,# val records 47991 , # test records 14552\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2009-08-31 # train records 96182 ,# val records 46419 , # test records 7653\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2010-08-31 # train records 105203 ,# val records 38716 , # test records 9794\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2011-08-31 # train records 109510 ,# val records 34937 , # test records 12978\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2012-08-31 # train records 108297 ,# val records 39748 , # test records 12468\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2013-08-31 # train records 104877 ,# val records 43094 , # test records 15537\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2014-08-31 # train records 102934 ,# val records 45393 , # test records 17526\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2015-08-31 # train records 99980 ,# val records 52517 , # test records 13529\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2016-08-31 # train records 101908 ,# val records 55101 , # test records 12399\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2017-08-31 # train records 113781 ,# val records 49648 , # test records 15613\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2018-08-31 # train records 122072 ,# val records 50289 , # test records 16489\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2019-08-31 # train records 123681 ,# val records 55523 , # test records 18226\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2020-08-31 # train records 129267 ,# val records 55692 , # test records 15232\n",
      "Train period: 2014-01-31 - 2019-01-31 ,val period: 2019-01-31 - 2021-01-31 , Test period 2021-01-31 - 2021-08-31 # train records 133811 ,# val records 56439 , # test records 16308\n",
      "R2OOS Linear Regression Bottom:  0.024892869274369733\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'risk_premium'])]\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "predictions_bottom = []\n",
    "y_test_list_bottom =[]\n",
    "dates_bottom = []\n",
    "dic_r2_all_bottom = {}\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = lm.predict(X_test) \n",
    "    predictions_bottom.append(preds)\n",
    "    dates_bottom.append(y_test.index)\n",
    "    y_test_list_bottom.append(y_test)\n",
    "    \n",
    "    r2_bottom = 1-np.sum(pow(y_test-preds,2))/np.sum(pow(y_test,2))\n",
    "    dic_r2_all_bottom[\"r2.\" + str(y_test.index)] = r2\n",
    "    \n",
    "\n",
    "predictions_all_bottom= np.concatenate(predictions_bottom, axis=0)\n",
    "y_test_list_all_bottom= np.concatenate(y_test_list_bottom, axis=0) \n",
    "dates_all_bottom= np.concatenate(dates_bottom, axis=0)\n",
    "\n",
    "R2OOS_LR_bottom = 1-np.sum(pow(y_test_list_all_bottom-predictions_all_bottom,2))/np.sum(pow(y_test_list_all_bottom,2))\n",
    "print(\"R2OOS Linear Regression Bottom: \", R2OOS_LR_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR-7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Sample</th>\n",
       "      <td>0.035660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Large Firms</th>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Small Firms</th>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LR-7\n",
       "Full Sample  0.035660\n",
       "Large Firms  0.024893\n",
       "Small Firms  0.024893"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = np.array([[R2OOS_LR],\n",
    "                  [R2OOS_LR_top],\n",
    "                  [R2OOS_LR_bottom]])\n",
    "\n",
    "r2_lm = pd.DataFrame(chart, columns=['LR-7'],\n",
    "                     index=['Full Sample', 'Large Firms', 'Small Firms'])\n",
    "\n",
    "r2_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lm.to_csv(r'r2_lr-7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['permno','permno','DATE','DATE2','mvel1','risk_premium', 'year'])].tolist()\n",
    "df['YEAR'] = df['DATE'].dt.year\n",
    "\n",
    "X_train = df[features].loc[(df['YEAR']>=2012) & (df['YEAR']<=2016)]\n",
    "y_train = df['risk_premium'].loc[(df['YEAR']>=2012) & (df['YEAR']<=2016)]\n",
    "\n",
    "X_val = df[features].loc[(df['YEAR']>=2017) & (df['YEAR']<=2018)]\n",
    "y_val = df['risk_premium'].loc[(df['YEAR']>=2017) & (df['YEAR']<=2018)]\n",
    "\n",
    "\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X_train, y_train)\n",
    "y_pred_train = lm_model.predict(X_train) \n",
    "\n",
    "y_pred_val = lm_model.predict(X_val) \n",
    "\n",
    "r2_score_train = r2_score(y_train, y_pred_train)\n",
    "r2_score_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "print(f'R2 score on training set: {r2_score_train}')\n",
    "print(f'R2 score on validation set: {r2_score_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in features:\n",
    "    globals()['df_' + str(j)] =  df.copy()\n",
    "    globals()['df_' + str(j)][str(j)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "    \n",
    "for j in features:\n",
    "    df_var = globals()['df_' + str(j)]\n",
    "    \n",
    "    X_train = df_var[features].loc[(df_var[\"year\"]>=2012) & (df_var[\"year\"]<=2016)]\n",
    "    y_train = df_var['risk_premium'].loc[(df_var[\"year\"]>=2012) & (df_var[\"year\"]<=2016)]\n",
    "\n",
    "    X_val = df_var[features].loc[(df_var[\"year\"]>=2017) & (df_var[\"year\"]<=2018)]\n",
    "    y_val = df_var['risk_premium'].loc[(df_var[\"year\"]>=2017) & (df_var[\"year\"]<=2018)]\n",
    "    \n",
    "    lm_model = LinearRegression()\n",
    "    lm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = lm_model.predict(X_train) \n",
    "\n",
    "    y_pred_val = lm_model.predict(X_val) \n",
    "\n",
    "    r2_score_train = r2_score(y_train, y_pred_train)\n",
    "    r2_score_val = r2_score(y_val, y_pred_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predictions_all.tolist()\n",
    "y_true = y_test_list_all.tolist()\n",
    "i = dates_all.tolist()\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'identifier': i,\n",
    "     'yhat': yhat,\n",
    "     'y_true': y_true\n",
    "    })\n",
    "\n",
    "results[\"identifier\"]= results[\"identifier\"].astype(\"str\")\n",
    "results[\"date\"] = results[\"identifier\"].str[12:22]\n",
    "results[\"id\"] = results[\"identifier\"].str[35:40]\n",
    "results.drop([\"identifier\"],axis = 1, inplace=True)\n",
    "results['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n",
    "results['MonthYear'] = results['date'].dt.to_period('M')\n",
    "results = results.sort_values(by = ['date', 'id'], ascending = True)\n",
    "results = results.set_index(['MonthYear','id'])\n",
    "results.head()\n",
    "\n",
    "results['yhat'] = results['yhat'].apply(lambda x: x[0])\n",
    "results['y_true'] = results['y_true'].apply(lambda x: x[0])\n",
    "\n",
    "data = df[['mvel12', 'macro_tbl', 'macro_svar']].copy()\n",
    "data.reset_index(inplace=True)\n",
    "data['permno2'] = data['permno2'].astype('str')\n",
    "data['MonthYear'] = data['DATE2'].dt.to_period('M')\n",
    "data.drop('DATE2', axis=1, inplace=True)\n",
    "data.rename(columns={'permno2': 'id'}, inplace=True)\n",
    "data.rename(columns={'mvel12': 'market_cap'}, inplace=True)\n",
    "data.rename(columns={'macro_tbl': 'risk_free_rate'}, inplace=True)\n",
    "data = data.set_index(['MonthYear','id'])\n",
    "\n",
    "bigdata = pd.merge(results, data,left_index=True, right_index=True)\n",
    "bigdata.reset_index(inplace=True)\n",
    "bigdata\n",
    "bigdata['returns'] = bigdata['y_true'] + bigdata['risk_free_rate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata.to_csv('predictions/lm_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata['MonthYear1'] = bigdata['MonthYear'].copy()\n",
    "bigdata['MonthYear'] = bigdata['MonthYear'].astype('int64')\n",
    "bigdata['NumMonth'] = bigdata['MonthYear'] - 155\n",
    "bigdata['NumMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>id</th>\n",
       "      <th>yhat</th>\n",
       "      <th>y_true</th>\n",
       "      <th>date</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>risk_free_rate</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>returns</th>\n",
       "      <th>MonthYear1</th>\n",
       "      <th>NumMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>10137</td>\n",
       "      <td>-12.604112</td>\n",
       "      <td>-8.6263</td>\n",
       "      <td>1983-01-31</td>\n",
       "      <td>-0.729231</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-8.623223</td>\n",
       "      <td>1983-01</td>\n",
       "      <td>-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156</td>\n",
       "      <td>10145</td>\n",
       "      <td>-13.838361</td>\n",
       "      <td>-1.1502</td>\n",
       "      <td>1983-01-31</td>\n",
       "      <td>-0.710769</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-1.147123</td>\n",
       "      <td>1983-01</td>\n",
       "      <td>-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>10161</td>\n",
       "      <td>-13.794653</td>\n",
       "      <td>7.9920</td>\n",
       "      <td>1983-01-31</td>\n",
       "      <td>-0.366154</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>7.995077</td>\n",
       "      <td>1983-01</td>\n",
       "      <td>-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156</td>\n",
       "      <td>10225</td>\n",
       "      <td>-12.695789</td>\n",
       "      <td>-8.6450</td>\n",
       "      <td>1983-01-31</td>\n",
       "      <td>0.329231</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-8.641924</td>\n",
       "      <td>1983-01</td>\n",
       "      <td>-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156</td>\n",
       "      <td>10233</td>\n",
       "      <td>-12.665246</td>\n",
       "      <td>-14.3907</td>\n",
       "      <td>1983-01-31</td>\n",
       "      <td>-0.070769</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-14.387623</td>\n",
       "      <td>1983-01</td>\n",
       "      <td>-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620975</th>\n",
       "      <td>612</td>\n",
       "      <td>93393</td>\n",
       "      <td>-3.024942</td>\n",
       "      <td>-5.4710</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>-0.964940</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>-5.470602</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620976</th>\n",
       "      <td>612</td>\n",
       "      <td>93419</td>\n",
       "      <td>-3.889795</td>\n",
       "      <td>-2.4747</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>-0.098805</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>-2.474302</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620977</th>\n",
       "      <td>612</td>\n",
       "      <td>93423</td>\n",
       "      <td>-3.422159</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>-0.258167</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.233698</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620978</th>\n",
       "      <td>612</td>\n",
       "      <td>93427</td>\n",
       "      <td>-3.742533</td>\n",
       "      <td>1.6799</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>-0.267729</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1.680298</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620979</th>\n",
       "      <td>612</td>\n",
       "      <td>93436</td>\n",
       "      <td>-3.021769</td>\n",
       "      <td>12.3906</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>0.976892</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>12.390999</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620980 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MonthYear     id       yhat   y_true       date  market_cap  \\\n",
       "0             156  10137 -12.604112  -8.6263 1983-01-31   -0.729231   \n",
       "1             156  10145 -13.838361  -1.1502 1983-01-31   -0.710769   \n",
       "2             156  10161 -13.794653   7.9920 1983-01-31   -0.366154   \n",
       "3             156  10225 -12.695789  -8.6450 1983-01-31    0.329231   \n",
       "4             156  10233 -12.665246 -14.3907 1983-01-31   -0.070769   \n",
       "...           ...    ...        ...      ...        ...         ...   \n",
       "620975        612  93393  -3.024942  -5.4710 2021-01-29   -0.964940   \n",
       "620976        612  93419  -3.889795  -2.4747 2021-01-29   -0.098805   \n",
       "620977        612  93423  -3.422159   0.2333 2021-01-29   -0.258167   \n",
       "620978        612  93427  -3.742533   1.6799 2021-01-29   -0.267729   \n",
       "620979        612  93436  -3.021769  12.3906 2021-01-29    0.976892   \n",
       "\n",
       "        risk_free_rate  macro_svar    returns MonthYear1  NumMonth  \n",
       "0             0.003077    0.003077  -8.623223    1983-01       -95  \n",
       "1             0.003077    0.003077  -1.147123    1983-01       -95  \n",
       "2             0.003077    0.003077   7.995077    1983-01       -95  \n",
       "3             0.003077    0.003077  -8.641924    1983-01       -95  \n",
       "4             0.003077    0.003077 -14.387623    1983-01       -95  \n",
       "...                ...         ...        ...        ...       ...  \n",
       "620975        0.000398    0.000398  -5.470602    2021-01       361  \n",
       "620976        0.000398    0.000398  -2.474302    2021-01       361  \n",
       "620977        0.000398    0.000398   0.233698    2021-01       361  \n",
       "620978        0.000398    0.000398   1.680298    2021-01       361  \n",
       "620979        0.000398    0.000398  12.390999    2021-01       361  \n",
       "\n",
       "[620980 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata = pd.merge(results, data,left_index=True, right_index=True)\n",
    "bigdata.reset_index(inplace=True)\n",
    "bigdata['returns'] = bigdata['y_true'] + bigdata['risk_free_rate']\n",
    "bigdata['MonthYear1'] = bigdata['MonthYear'].copy()\n",
    "bigdata['MonthYear'] = bigdata['MonthYear'].astype('int64')\n",
    "bigdata['NumMonth'] = bigdata['MonthYear'] - 251\n",
    "bigdata['NumMonth'].unique()\n",
    "bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bigdata['NumMonth'].unique():\n",
    "    globals()['df_' + str(i)] = bigdata[bigdata['NumMonth'] == i]\n",
    "\n",
    "for i in bigdata[\"NumMonth\"].unique():\n",
    "    globals()['df_' + str(i)][\"rank\"]= globals()['df_' + str(i)]['yhat'].rank(method='first')\n",
    "    \n",
    "for i in bigdata[\"NumMonth\"].unique():\n",
    "    globals()['df_' + str(i)][\"DecileRank\"]=pd.qcut(globals()['df_' + str(i)]['rank'].values, 10, labels = False)\n",
    "\n",
    "#Drop normal rank, retain only decile ranks \n",
    "for i in bigdata[\"NumMonth\"].unique():\n",
    "     globals()['df_' + str(i)].drop('rank', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "for i in bigdata[\"NumMonth\"].unique():\n",
    "    for j,g in globals()['df_' + str(i)].groupby('DecileRank'):\n",
    "        globals()['df_' + str(i)+ \"_\" + str(j)] =  g\n",
    "\n",
    "for j in np.arange(0,10,1):\n",
    "    globals()['rank_' + str(j)] = pd.concat([globals()['df_1_'+ str(j)], globals()['df_2_'+ str(j)]], axis=0)\n",
    "    \n",
    "# Generate 10 Dataframes for the 10 Decile portfolios 0-9: rank_9: top portfolio, rank_0: bottom portfolio\n",
    "for i in np.arange(2,457,1):\n",
    "    for j in np.arange(0,10,1):\n",
    "        globals()['rank_' + str(j)] = pd.concat([globals()['rank_' + str(j)], globals()['df_' + str(i+1)+ \"_\" + str(j)]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(0, 10, 1):\n",
    "    globals()['rank_' + str(j)]['residuals'] = globals()['rank_' + str(j)]['y_true'] - globals()['rank_' + str(j)]['yhat']\n",
    "    globals()['rank_' + str(j)] = globals()['rank_' + str(j)].sort_values(['NumMonth','residuals'],\n",
    "                   ascending=[True, True]).groupby(['MonthYear'],\n",
    "                                                                  as_index=False,\n",
    "                                                                  sort=False).nth(list(range(0, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in np.arange(0,10,1):\n",
    "    globals()['rank_' + str(j)][\"eq_weights\"] = 1/globals()['rank_' + str(j)].groupby('MonthYear')[\"id\"].transform('size')\n",
    "    globals()['rank_' + str(j)]['excess_return_stock_ew'] = globals()['rank_' + str(j)][\"y_true\"]*globals()['rank_' + str(j)][\"eq_weights\"]\n",
    "    globals()['rank_' + str(j)]['return_stock_ew'] = globals()['rank_' + str(j)][\"returns\"]*globals()['rank_' + str(j)][\"eq_weights\"]\n",
    "    globals()['rank_' + str(j)]['excess_return_portfolio_ew'] = globals()['rank_' + str(j)].groupby('MonthYear')[\"excess_return_stock_ew\"].transform('sum')\n",
    "    globals()['rank_' + str(j)]['return_portfolio_ew'] = globals()['rank_' + str(j)].groupby('MonthYear')[\"return_stock_ew\"].transform('sum')\n",
    "    globals()['rank_' + str(j)]['pred_excess_return_stock_ew'] = globals()['rank_' + str(j)][\"yhat\"]*globals()['rank_' + str(j)][\"eq_weights\"]\n",
    "    globals()['rank_' + str(j)]['pred_excess_return_portfolio_ew'] = globals()['rank_' + str(j)].groupby('MonthYear')[\"pred_excess_return_stock_ew\"].transform('sum')\n",
    "\n",
    "    globals()['monthly_rank_' + str(j)] = globals()['rank_' + str(j)][[\"MonthYear1\", \"DecileRank\",\n",
    "                                                                      \"excess_return_portfolio_ew\",\n",
    "                                                                      \"pred_excess_return_portfolio_ew\",\n",
    "                                                                      \"return_portfolio_ew\"]]\n",
    "\n",
    "    globals()['monthly_rank_' + str(j)]=globals()['monthly_rank_' + str(j)].drop_duplicates()\n",
    "\n",
    "    globals()[\"ew_mean_return_rank_\" +  str(j)]= globals()['monthly_rank_' + str(j)][\"excess_return_portfolio_ew\"].mean()\n",
    "    #Time-series average of predicted excess returns\n",
    "    globals()[\"ew_mean_pred_return_rank_\" +  str(j)]= globals()['monthly_rank_' + str(j)][\"pred_excess_return_portfolio_ew\"].mean()\n",
    "    #Standard deviation of realized excess returns\n",
    "    globals()[\"std_ew_rank_\" +  str(j)]= globals()['monthly_rank_' + str(j)][\"excess_return_portfolio_ew\"].std()\n",
    "    #Annualized sharpe ratio of realized excess returns\n",
    "    globals()[\"sharpe_ew_rank_\" +  str(j)]= (globals()['monthly_rank_' + str(j)][\"excess_return_portfolio_ew\"].mean()/globals()['monthly_rank_' + str(j)][\"return_portfolio_ew\"].std())* np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "      <th>Real</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low (L)</th>\n",
       "      <td>-3.68%</td>\n",
       "      <td>-7.02%</td>\n",
       "      <td>7.49%</td>\n",
       "      <td>-3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.44%</td>\n",
       "      <td>-6.22%</td>\n",
       "      <td>6.34%</td>\n",
       "      <td>-3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.31%</td>\n",
       "      <td>-5.93%</td>\n",
       "      <td>5.68%</td>\n",
       "      <td>-3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.19%</td>\n",
       "      <td>-5.77%</td>\n",
       "      <td>5.41%</td>\n",
       "      <td>-3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.09%</td>\n",
       "      <td>-6.04%</td>\n",
       "      <td>5.61%</td>\n",
       "      <td>-3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.00%</td>\n",
       "      <td>-5.92%</td>\n",
       "      <td>5.37%</td>\n",
       "      <td>-3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.90%</td>\n",
       "      <td>-5.72%</td>\n",
       "      <td>5.20%</td>\n",
       "      <td>-3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.79%</td>\n",
       "      <td>-5.75%</td>\n",
       "      <td>5.35%</td>\n",
       "      <td>-3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.65%</td>\n",
       "      <td>-5.80%</td>\n",
       "      <td>5.47%</td>\n",
       "      <td>-3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High (H)</th>\n",
       "      <td>-2.42%</td>\n",
       "      <td>-6.00%</td>\n",
       "      <td>6.14%</td>\n",
       "      <td>-3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred    Real    Std Sharpe\n",
       "Low (L)   -3.68%  -7.02%  7.49%  -3.25\n",
       "2         -3.44%  -6.22%  6.34%  -3.40\n",
       "3         -3.31%  -5.93%  5.68%  -3.62\n",
       "4         -3.19%  -5.77%  5.41%  -3.70\n",
       "5         -3.09%  -6.04%  5.61%  -3.73\n",
       "6         -3.00%  -5.92%  5.37%  -3.82\n",
       "7         -2.90%  -5.72%  5.20%  -3.81\n",
       "8         -2.79%  -5.75%  5.35%  -3.73\n",
       "9         -2.65%  -5.80%  5.47%  -3.67\n",
       "High (H)  -2.42%  -6.00%  6.14%  -3.38"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "chart_np = np.array([[ew_mean_pred_return_rank_0, ew_mean_return_rank_0, std_ew_rank_0, sharpe_ew_rank_0],\n",
    "                     [ew_mean_pred_return_rank_1, ew_mean_return_rank_1, std_ew_rank_1, sharpe_ew_rank_1],\n",
    "                     [ew_mean_pred_return_rank_2, ew_mean_return_rank_2, std_ew_rank_2, sharpe_ew_rank_2],\n",
    "                     [ew_mean_pred_return_rank_3, ew_mean_return_rank_3, std_ew_rank_3, sharpe_ew_rank_3],\n",
    "                     [ew_mean_pred_return_rank_4, ew_mean_return_rank_4, std_ew_rank_4, sharpe_ew_rank_4],\n",
    "                     [ew_mean_pred_return_rank_5, ew_mean_return_rank_5, std_ew_rank_5, sharpe_ew_rank_5],\n",
    "                     [ew_mean_pred_return_rank_6, ew_mean_return_rank_6, std_ew_rank_6, sharpe_ew_rank_6],\n",
    "                     [ew_mean_pred_return_rank_7, ew_mean_return_rank_7, std_ew_rank_7, sharpe_ew_rank_7],\n",
    "                     [ew_mean_pred_return_rank_8, ew_mean_return_rank_8, std_ew_rank_8, sharpe_ew_rank_8],\n",
    "                     [ew_mean_pred_return_rank_9, ew_mean_return_rank_9, std_ew_rank_9, sharpe_ew_rank_9]])\n",
    "\n",
    "ew_df = pd.DataFrame(chart_np, columns=['Pred', 'Real', 'Std', 'Sharpe'],\n",
    "                              index=['Low (L)', '2', '3', '4', '5','6','7','8',\"9\",'High (H)'])\n",
    "ew_df['Pred'] = pd.Series([\"{0:.2f}%\".format(val) for val in ew_df['Pred']], index = ew_df.index)\n",
    "ew_df['Real'] = pd.Series([\"{0:.2f}%\".format(val) for val in ew_df['Real']], index = ew_df.index)\n",
    "ew_df['Std'] = pd.Series([\"{0:.2f}%\".format(val) for val in ew_df['Std']], index = ew_df.index)\n",
    "ew_df['Sharpe'] = pd.Series([(\"%.2f\" % round(val, 2)) for val in ew_df['Sharpe']], index = ew_df.index)\n",
    "ew_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
